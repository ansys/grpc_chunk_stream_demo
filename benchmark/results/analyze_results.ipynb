{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## localhost performance with `iperf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `iperf` command line utility to get an upper limit for the performance of the `localhost` connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create a server listening on port 3000. We need to use `subprocess` manually to ensure the Jupyter process isn't blocked.\n",
    "    iperf_server_proc = subprocess.Popen(['iperf', '-s', '-p', '3000'])\n",
    "    # Create an iperf client\n",
    "    !iperf -c localhost -p 3000 -f M\n",
    "finally:\n",
    "    # Shut down the server\n",
    "    iperf_server_proc.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memcpy performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a point of comparison, we check the performance of in-process copying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_memcpy = pd.read_csv(\"memcpy.csv\")\n",
    "df_memcpy[\"bytes_per_second\"] = (df_memcpy[\"repetitions\"] *  df_memcpy[\"size_bytes\"]) / (df_memcpy[\"duration_nanoseconds\"] * 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x=\"size_bytes\",\n",
    "    y=\"bytes_per_second\",\n",
    "    ax=ax,\n",
    "    data=df_memcpy,\n",
    ")\n",
    "ax.set_xscale(\"log\", base=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading gRPC test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sync = pd.read_csv(\"sync.csv\", skipinitialspace=True)\n",
    "df_sync[\"execution_mode\"] = \"sync\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threaded = pd.read_csv(\"threaded_client.csv\", skipinitialspace=True)\n",
    "df_threaded[\"execution_mode\"] = \"threaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_sync, df_threaded])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"vec_size_bytes\"] = df[\"vec_size\"] * df[\"type_size\"]\n",
    "# The reported chunk_size is given in multiples of the data size, even for\n",
    "# the binary chunking method.\n",
    "df[\"chunk_size_bytes\"] = df[\"chunk_size\"] * df[\"type_size\"]\n",
    "\n",
    "df[\"runtime_normalized_seconds\"] = 1e-6 * df[\"runtime\"] / df[\"num_repetitions\"]\n",
    "df[\"bytes_per_second\"] = df[\"vec_size_bytes\"] / df[\"runtime_normalized_seconds\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data analysis, an important point is that the `GetArrayChunked` and `GetArrayBinaryChunked` methods have measurements for different chunk sizes. As such, the average runtimes are not directly comparable. We want to first see how chunk size affects performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe containing only the methods with chunking\n",
    "df_chunked = df[df[\"chunk_size\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunked[\"vec_size_bytes\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show the performance as a function of chunk size, for a single vector size where we have a reasonable number of measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15), sharey=True)\n",
    "for type_id, ax in zip(df_chunked[\"type_id\"].unique(), axes.flatten()):\n",
    "    sns.lineplot(\n",
    "        ax=ax,\n",
    "        x=\"chunk_size_bytes\", \n",
    "        y=\"bytes_per_second\", \n",
    "        hue=\"method_id\", \n",
    "        data=df_chunked[(df_chunked[\"type_id\"] == type_id) & (df_chunked[\"vec_size_bytes\"] == 16777216) & (df_chunked[\"execution_mode\"] == \"sync\")]\n",
    "    )\n",
    "    ax.set_xscale(\"log\", base=2)\n",
    "    ax.set_title(type_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now pick the best chunksize for each combination of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_chunksize = df.groupby([\"vec_size_bytes\", \"type_id\", \"method_id\", \"execution_mode\", \"chunk_size_bytes\"])\n",
    "df_aggregate = df_by_chunksize.agg({\"runtime_normalized_seconds\": np.mean}).reset_index()\n",
    "grouped = df_aggregate.groupby([\"vec_size_bytes\", \"type_id\", \"method_id\", \"execution_mode\"])\n",
    "df_best_chunksize = df_aggregate.loc[grouped[\"runtime_normalized_seconds\"].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_chunksize[\"bytes_per_second\"] = df_best_chunksize[\"vec_size_bytes\"] / df_best_chunksize[\"runtime_normalized_seconds\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of the different methods. For visibility, we only show a few data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "for execution_mode, ax in zip([\"sync\", \"threaded\"], axes):\n",
    "    sns.lineplot(\n",
    "        x=\"vec_size_bytes\", \n",
    "        y=\"bytes_per_second\", \n",
    "        hue=\"method_id\", \n",
    "        style=\"type_id\",\n",
    "        data=df_best_chunksize[(df_best_chunksize[\"execution_mode\"] == execution_mode) & (df_best_chunksize[\"type_id\"].isin([\"sfixed64\", \"sfixed32\"]))],\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f\"execution_mode={execution_mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunked[df_chunked[\"vec_size_bytes\"] == 67108864]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "#sns.set(rc={\"figure.figsize\":(12, 10)}, yscale=\"log\")\n",
    "sns.lineplot(\n",
    "    x=\"vec_size_bytes\", \n",
    "    y=\"chunk_size_bytes\", \n",
    "    hue=\"method_id\", \n",
    "    #style=\"type_id\"\n",
    "    ax=ax,\n",
    "    data=df_best_chunksize[(df_best_chunksize[\"chunk_size_bytes\"] != 0) & (df_best_chunksize[\"type_id\"] == \"sfixed64\") & (df_best_chunksize[\"execution_mode\"] == \"sync\")]\n",
    ")\n",
    "ax.set_xscale(\"log\", base=2)\n",
    "ax.set_yscale(\"log\", base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
